{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a DAG for model training\n",
    "# Components:\n",
    "# 1. Data ingestion\n",
    "# 2. Data preprocessing\n",
    "# 3. Model training\n",
    "# 4. Model evaluation\n",
    "# 5. Model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting trainingFlow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile trainingFlow.py\n",
    "\n",
    "# Importing libraries related with metaflow\n",
    "from metaflow import FlowSpec, step, Parameter, conda, batch\n",
    "\n",
    "import optuna\n",
    "import mlflow\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import datetime\n",
    "\n",
    "def setup_env():\n",
    "    import os\n",
    "\n",
    "    os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n",
    "    os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n",
    "    os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://localhost:9000\"\n",
    "    os.environ[\"MYSQL_DATABASE\"] = \"mlflow_database\"\n",
    "    os.environ[\"MYSQL_USER\"] = \"mlflow_user\"\n",
    "    os.environ[\"MYSQL_PASSWORD\"] = \"mlflow\"\n",
    "    os.environ[\"MYSQL_ROOT_PASSWORD\"] = \"mysql\"\n",
    "\n",
    "    # requirements = {\n",
    "    #         \"boto3\":\"1.26.37\",\n",
    "    #         \"mlflow\":\"2.1.1\",\n",
    "    #         \"scikit-learn\":\"1.2.0\",\n",
    "    #         \"pandas\":\"1.5.2\",\n",
    "    #         \"optuna\":\"3.0.5\",\n",
    "    #     }\n",
    "    import mlflow\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(\"mlflow-tutorial\")\n",
    "\n",
    "\n",
    "\n",
    "def get_data():\n",
    "    from sklearn import datasets\n",
    "\n",
    "    X, y = datasets.make_classification(n_samples=1000, n_features=4, n_informative=4, n_redundant=0, n_classes=3, n_clusters_per_class=1, class_sep=0.5, random_state=40)\n",
    "    return X, y\n",
    "\n",
    "class trainingFlow(FlowSpec):\n",
    "    @step\n",
    "    def start(self):\n",
    "        self.next(self.ingest_data)\n",
    "    \n",
    "    #@conda(libraries=requirements, python='3.9.5')\n",
    "    @step\n",
    "    def ingest_data(self):\n",
    "        self.X, self.y = get_data()\n",
    "        self.next(self.hyperparameter_tuning)\n",
    "        \n",
    "    \n",
    "    #@conda(libraries=requirements,python='3.9.5')\n",
    "    @step\n",
    "    def hyperparameter_tuning(self):\n",
    "        setup_env()\n",
    "        def optimize_rf(trial):\n",
    "            with mlflow.start_run(run_name=f\"optuna-hp-{trial.number}-{datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"):\n",
    "                # Set the hyperparameter values that we want to optimize\n",
    "                n_estimators = trial.suggest_int('n_estimators', 1, 100)\n",
    "                max_depth = trial.suggest_int('max_depth', 2, 10)\n",
    "                min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "                min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "                max_features = trial.suggest_float('max_features', 0.1, 1.0)\n",
    "                \n",
    "                \n",
    "                # Create a random forest classifier using the suggested hyperparameters\n",
    "                rf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth,\n",
    "                                            min_samples_split=min_samples_split,\n",
    "                                            min_samples_leaf=min_samples_leaf,\n",
    "                                            max_features=max_features)\n",
    "                \n",
    "                # Use cross-validation to evaluate the performance of the classifier\n",
    "                scores = cross_val_score(rf, self.X, self.y, cv=5)\n",
    "                \n",
    "                # Log the hyperparameters and cross-validation scores to MLflow\n",
    "                mlflow.log_param('n_estimators', n_estimators)\n",
    "                mlflow.log_param('max_depth', max_depth)\n",
    "                mlflow.log_param('min_samples_split', min_samples_split)\n",
    "                mlflow.log_param('min_samples_leaf', min_samples_leaf)\n",
    "                mlflow.log_param('max_features', max_features)\n",
    "                mlflow.log_metric('mean_cv_score', scores.mean())\n",
    "            \n",
    "            # Return the mean of the cross-validation scores as the objective value\n",
    "            return scores.mean()\n",
    "        \n",
    "        # Create an Optuna study\n",
    "        study = optuna.create_study()\n",
    "\n",
    "        # Run the optimization loop\n",
    "        study.optimize(optimize_rf, n_trials=100)\n",
    "\n",
    "        # Get the best hyperparameter values\n",
    "        self.best_params = study.best_params\n",
    "        \n",
    "        self.next(self.train_final_model)\n",
    "        \n",
    "    \n",
    "    #@conda(libraries=requirements,python='3.9.5')\n",
    "    @step\n",
    "    def train_final_model(self):\n",
    "        setup_env()\n",
    "        with mlflow.start_run(run_name=f\"optuna-hp-final\"):\n",
    "            # Create the final model using the best hyperparameters\n",
    "            final_model = RandomForestClassifier(**self.best_params)\n",
    "\n",
    "            # Train the final model on the entire dataset\n",
    "            final_model.fit(self.X, self.y)\n",
    "\n",
    "            # Log the model to the \"Models\" section\n",
    "            mlflow.sklearn.log_model(final_model, \"random_forest_model\", registered_model_name=\"random_forest_model\")\n",
    "\n",
    "        self.next(self.end)\n",
    "        \n",
    "    @step\n",
    "    def end(self):\n",
    "        pass\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    trainingFlow()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run -p 3000:3000 -e METAFLOW_SERVICE=http://localhost:8083/ metaflow-ui:latest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "productionalization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f3ab8483b541a64f441fab950358594b3cd6524f788fc4c237ce6fe8cca2ea8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
