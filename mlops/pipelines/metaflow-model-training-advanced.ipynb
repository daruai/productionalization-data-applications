{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a DAG for model training\n",
    "# Components:\n",
    "# 1. Data ingestion\n",
    "# 2. Data preprocessing\n",
    "# 3. Model training\n",
    "# 4. Model evaluation\n",
    "# 5. Model deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting trainingFlow.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile trainingFlow.py\n",
    "\n",
    "# Importing libraries related with metaflow\n",
    "from metaflow import FlowSpec, step, Parameter, conda, batch\n",
    "\n",
    "import optuna\n",
    "import mlflow\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "import datetime\n",
    "from mlopshelpers.data.dataset import get_data, split_data, preprocess_data\n",
    "from mlopshelpers.training.model_train import train_random_forest, cv_random_forest\n",
    "from mlopshelpers.evaluation.evaluate import evaluate_classification\n",
    "\n",
    "def setup_env():\n",
    "    import os\n",
    "\n",
    "    # os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minio\"\n",
    "    # os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minio123\"\n",
    "    # os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = \"http://localhost:9000\"\n",
    "    # os.environ[\"MYSQL_DATABASE\"] = \"mlflow_database\"\n",
    "    # os.environ[\"MYSQL_USER\"] = \"mlflow_user\"\n",
    "    # os.environ[\"MYSQL_PASSWORD\"] = \"mlflow\"\n",
    "    # os.environ[\"MYSQL_ROOT_PASSWORD\"] = \"mysql\"\n",
    "\n",
    "    # requirements = {\n",
    "    #         \"boto3\":\"1.26.37\",\n",
    "    #         \"mlflow\":\"2.1.1\",\n",
    "    #         \"scikit-learn\":\"1.2.0\",\n",
    "    #         \"pandas\":\"1.5.2\",\n",
    "    #         \"optuna\":\"3.0.5\",\n",
    "    #     }\n",
    "    import mlflow\n",
    "    mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "    mlflow.set_experiment(\"mlflow-tutorial\")\n",
    "\n",
    "class trainingFlow(FlowSpec):\n",
    "    @step\n",
    "    def start(self):\n",
    "        self.next(self.ingest_data)\n",
    "    \n",
    "    #@conda(libraries=requirements, python='3.9.5')\n",
    "    @step\n",
    "    def ingest_data(self):\n",
    "        self.X, self.y = get_data(\"iris\")\n",
    "        self.next(self.data_split)\n",
    "    \n",
    "    @step\n",
    "    def data_split(self):\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = split_data(self.X, self.y)\n",
    "        self.next(self.data_preprocessing)\n",
    "        \n",
    "    @step\n",
    "    def data_preprocessing(self):\n",
    "        self.X_train, self.X_test, _ = preprocess_data(self.X_train, self.X_test, \n",
    "                                                       continuous_features=['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], \n",
    "                                                       categorical_features=[])\n",
    "        self.next(self.hyperparameter_tuning)\n",
    "    \n",
    "    #@conda(libraries=requirements,python='3.9.5')\n",
    "    @step\n",
    "    def hyperparameter_tuning(self):\n",
    "        setup_env()\n",
    "        def optimize_rf(trial):\n",
    "            with mlflow.start_run(run_name=f\"optuna-hp-{trial.number}-{datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')}\"):\n",
    "                # Set the hyperparameter values that we want to optimize\n",
    "                n_estimators = trial.suggest_int('n_estimators', 1, 100)\n",
    "                max_depth = trial.suggest_int('max_depth', 2, 10)\n",
    "                min_samples_split = trial.suggest_int('min_samples_split', 2, 20)\n",
    "                min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20)\n",
    "                max_features = trial.suggest_float('max_features', 0.1, 1.0)\n",
    "                \n",
    "                \n",
    "                score = cv_random_forest(self.X_train, self.y_train, \n",
    "                                 {'n_estimators': n_estimators,\n",
    "                                  'max_depth': max_depth,\n",
    "                                  'min_samples_split': min_samples_split,\n",
    "                                  'min_samples_leaf': min_samples_leaf,\n",
    "                                  'max_features': max_features}\n",
    "                                                  )\n",
    "                \n",
    "                # Log the hyperparameters and cross-validation scores to MLflow\n",
    "                mlflow.log_param('n_estimators', n_estimators)\n",
    "                mlflow.log_param('max_depth', max_depth)\n",
    "                mlflow.log_param('min_samples_split', min_samples_split)\n",
    "                mlflow.log_param('min_samples_leaf', min_samples_leaf)\n",
    "                mlflow.log_param('max_features', max_features)\n",
    "                mlflow.log_metric('mean_cv_score', score)\n",
    "            \n",
    "            # Return the mean of the cross-validation scores as the objective value\n",
    "            return score\n",
    "        \n",
    "        # Create an Optuna study\n",
    "        study = optuna.create_study()\n",
    "\n",
    "        # Run the optimization loop\n",
    "        study.optimize(optimize_rf, n_trials=100)\n",
    "\n",
    "        # Get the best hyperparameter values\n",
    "        self.best_params = study.best_params\n",
    "        \n",
    "        self.next(self.train_final_model)\n",
    "        \n",
    "    \n",
    "    #@conda(libraries=requirements,python='3.9.5')\n",
    "    @step\n",
    "    def train_final_model(self):\n",
    "        setup_env()\n",
    "        with mlflow.start_run(run_name=f\"optuna-hp-final\"):\n",
    "            # Create the final model using the best hyperparameters\n",
    "            final_model = train_random_forest(self.X_train, self.y_train, self.best_params)\n",
    "            \n",
    "            y_pred = final_model.predict(self.X_test)\n",
    "            \n",
    "            metrics = evaluate_classification(self.y_test, y_pred, \"macro\")\n",
    "            \n",
    "            # Log hyperparameters to MLflow\n",
    "            for param_name, param_value in self.best_params.items():\n",
    "                mlflow.log_param(param_name, param_value)\n",
    "            \n",
    "            # Log metrics to MLflow\n",
    "            for metric_name, metric_value in metrics.items():\n",
    "                mlflow.log_metric(metric_name, metric_value)\n",
    "\n",
    "            # Log the model to the \"Models\" section\n",
    "            mlflow.sklearn.log_model(final_model, \"random_forest_model\", registered_model_name=\"random_forest_model\")\n",
    "\n",
    "        self.next(self.end)\n",
    "        \n",
    "    @step\n",
    "    def end(self):\n",
    "        pass\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    trainingFlow()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry shell\n",
    "# python trainingFlow.py\n",
    "# python trainingFlow.py run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docker run -p 3000:3000 -e METAFLOW_SERVICE=http://localhost:8083/ metaflow-ui:latest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "productionalization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f3ab8483b541a64f441fab950358594b3cd6524f788fc4c237ce6fe8cca2ea8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
